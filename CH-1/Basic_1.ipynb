{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3799c578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi there! How can I help you today ‚Äî a question, writing or coding help, planning something, or something else?\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "from load_dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "if os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    print(\"API KEY VARAIBLE EXIST\")\n",
    "else:\n",
    "   raise ValueError(\"OPENAI_API_KEY NOT FOUND\") \n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-5-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Hello!\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70aafe57",
   "metadata": {},
   "source": [
    "## LLM CALL \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9819b9f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Bro ‚Äî fun fact: wombats poop in perfect little cubes.  \\n\\nTheir intestines shape the poop into cubes so it doesn't roll away, which helps them mark territory and communicate. Wildly practical and oddly adorable. Want another one?\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "import os\n",
    "from load_dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "if os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    print(\"API KEY VARAIBLE EXIST\")\n",
    "else:\n",
    "   raise ValueError(\"OPENAI_API_KEY NOT FOUND\") \n",
    "llm_openai = ChatOpenAI(model=\"gpt-5-mini\", temperature=0)\n",
    "\n",
    "llm_openai.invoke(\"Bro, tell me a fun fact\").content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc4fb8d",
   "metadata": {},
   "source": [
    "### USING init_chat_model  a factory function that automatically initializes the correct chat model class based on the provider you specify, without needing to import provider-specific classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44005e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bro ‚Äî fun fact: wombats poop in perfect little cubes. They do it to stack the piles as territorial/attracting markers, and their uniquely-shaped, very slow-moving intestines are what mold the poop into cubes. Want another weird one?'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "from load_dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "if os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    print(\"API KEY VARAIBLE EXIST\")\n",
    "else:\n",
    "   raise ValueError(\"OPENAI_API_KEY NOT FOUND\") \n",
    "   \n",
    "llm = init_chat_model(\"gpt-5-mini\", model_provider=\"openai\")\n",
    "\n",
    "llm.invoke(\"Bro, tell me a fun fact\").content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b082ee2d",
   "metadata": {},
   "source": [
    "# MESSAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "edf2dd08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API KEY VARAIBLE EXIST\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Bro ‚Äî fun fact: bananas are technically berries, but strawberries aren‚Äôt. Wild, right? Botanically a ‚Äúberry‚Äù comes from one ovary (bananas, grapes, even tomatoes), while strawberries are aggregate fruits with seeds on the outside. Mind. Blown. ü§Øüçå'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "from load_dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "if os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    print(\"API KEY VARAIBLE EXIST\")\n",
    "else:\n",
    "   raise ValueError(\"OPENAI_API_KEY NOT FOUND\") \n",
    "\n",
    "llm_openai = ChatOpenAI(model=\"gpt-5-mini\", temperature=0)\n",
    "\n",
    "my_message = [\n",
    "    HumanMessage(content=\"Bro, tell me a fun fact?\"),\n",
    "    SystemMessage(content=\"You are a gen-z assistance. who always answer in afun way\")\n",
    "]\n",
    "\n",
    "llm_openai.invoke(my_message).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3a84c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API KEY VARAIBLE EXIST\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "from load_dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "if os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    print(\"API KEY VARAIBLE EXIST\")\n",
    "else\n",
    "   raise ValueError(\"OPENAI_API_KEY NOT FOUND\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9577c7",
   "metadata": {},
   "source": [
    "# PROMPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "14051ef1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Fun fact: Domestic cats can't taste sweetness ‚Äî they lack a functional sweet-taste receptor (a mutated Tas1r2 gene), so sugary foods don't register as sweet to them.\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "user_input =input(\"Enter a topic for fun fact : \")\n",
    "\n",
    "dynamic_prompt = PromptTemplate.from_template(\"Write a fun fact about {topic}\")\n",
    "\n",
    "ready_prompt = dynamic_prompt.invoke({\"topic\" : user_input})\n",
    "\n",
    "llm_openai.invoke(ready_prompt).content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0722284",
   "metadata": {},
   "source": [
    "## USING A ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6475719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Summary\\n- The code compiles but is an empty, public top-level class: public class Test { }.\\n- As-is it has no behavior or documentation. That may be fine temporarily, but in real code it should be improved for clarity, purpose, packaging and style.\\n\\nConcrete suggestions\\n\\n1) Give the class a meaningful name\\n- \"Test\" is generic and likely to collide with testing frameworks and other classes. Choose a name that describes the class responsibility (e.g., UserService, Customer, StringUtils).\\n\\n2) Put classes in a package\\n- Avoid the default package. Add a package declaration (e.g., package com.example.foo;). This prevents name clashes and is required for production builds and many tools.\\n\\n3) Add Javadoc\\n- At minimum document the class responsibility and any invariants or usage notes:\\n  /**\\n   * Brief description of what this class represents or does.\\n   */\\n\\n4) Don‚Äôt leave an empty public class\\n- If the class is intended to be a marker type use an interface or annotation, or document why it‚Äôs empty.\\n- If it‚Äôs a utility class, make it final with a private constructor and static methods.\\n- If it‚Äôs a POJO, add fields, constructors, getters, and override equals/hashCode/toString as appropriate.\\n\\n5) File name and layout\\n- Ensure the file is named Test.java (matching the public class) and is stored in a directory tree that matches the package.\\n\\n6) Consider access and extension semantics\\n- If not intended for extension, mark final.\\n- If intended to be abstract, declare abstract and include abstract methods or documentation.\\n\\n7) Unit tests and placement\\n- If this is a test class for JUnit, place it under the test source tree and annotate methods with @Test. Avoid naming collisions with framework classes.\\n\\nExamples\\n\\n- Utility class:\\npackage com.example.util;\\npublic final class StringUtils {\\n    private StringUtils() { } // prevent instantiation\\n    public static boolean isBlank(String s) {\\n        return s == null || s.trim().isEmpty();\\n    }\\n}\\n\\n- Simple immutable POJO:\\npackage com.example.model;\\npublic final class Person {\\n    private final String name;\\n    public Person(String name) { this.name = Objects.requireNonNull(name); }\\n    public String getName() { return name; }\\n    @Override public boolean equals(Object o) { /* implement */ }\\n    @Override public int hashCode() { /* implement */ }\\n    @Override public String toString() { return \"Person[name=\"+name+\"]\"; }\\n}\\n\\n- Marker intent: prefer interface/annotation:\\npackage com.example.marker;\\npublic interface Auditable { } // a marker interface\\n\\nWhen the current class is acceptable\\n- If this is a stub during iterative development or a placeholder, add a comment or TODO explaining the intent so others know it‚Äôs deliberate.\\n\\nIf you tell me the intended purpose of this class (utility, model/entity, marker, test, placeholder), I can suggest a concrete skeleton or implementation.'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-5-mini\")\n",
    "\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an expert {language} code reviewer. Provide constructive feedback.\"),\n",
    "    (\"human\", \"Review this code:\\n{code}\")\n",
    "])\n",
    "\n",
    "prompt = template.invoke({\n",
    "    \"language\": \"Java\",\n",
    "    \"code\": \"public class Test { }\"\n",
    "})\n",
    "\n",
    "llm.invoke(prompt).content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c370f90a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bro ‚Äî fun fact: honey basically never spoils. Archaeologists have found 3,000‚Äëyear‚Äëold jars of honey in Egyptian tombs that were still edible, thanks to honey‚Äôs low water content, acidity, and bee enzymes that make it inhospitable to bacteria.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_message = [\n",
    "    HumanMessage(content=\"Bro, tell me a fun fact about honey?\"),\n",
    "    SystemMessage(content=\"You are a gen-z assistance. who always answer in afun way\")\n",
    "]\n",
    "llm_openai.invoke(my_message).content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b654bc",
   "metadata": {},
   "source": [
    "PYDANTIC AND STURCTURE OUTPUT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c1554b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üö® CRITICAL CD4: 180 - Immediate action required\n",
      "‚ö†Ô∏è Patient overdue by 93 days\n",
      "Age: 45\n",
      "Outcome: Virological Failure\n",
      "Next Visit: 2026-01-30\n",
      "Alerts: Critical CD4 count; Treatment failure despite good adherence; Overdue by 3 days\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, field_validator, Field\n",
    "from datetime import date, timedelta\n",
    "from typing import Literal\n",
    "\n",
    "class LAMISPatient(BaseModel):\n",
    "    \"\"\"Production-ready patient model\"\"\"\n",
    "    \n",
    "    patient_id: str = Field(pattern=r\"^LAM\\d+$\")\n",
    "    name: str\n",
    "    date_of_birth: date\n",
    "    cd4_count: int\n",
    "    viral_load: int\n",
    "    regimen: str\n",
    "    adherence: Literal[\"Good\", \"Fair\", \"Poor\"]\n",
    "    last_visit: date\n",
    "    \n",
    "    # VALIDATORS - Data quality checks (V2 syntax)\n",
    "    \n",
    "    @field_validator('cd4_count')\n",
    "    @classmethod\n",
    "    def validate_cd4(cls, v: int) -> int:\n",
    "        \"\"\"Check CD4 range and warn\"\"\"\n",
    "        if v < 0 or v > 2000:\n",
    "            raise ValueError(f\"Invalid CD4: {v}\")\n",
    "        if v < 200:\n",
    "            print(f\"üö® CRITICAL CD4: {v} - Immediate action required\")\n",
    "        return v\n",
    "    \n",
    "    @field_validator('last_visit')\n",
    "    @classmethod\n",
    "    def check_overdue(cls, v: date) -> date:\n",
    "        \"\"\"Warn if visit is overdue\"\"\"\n",
    "        days_since = (date.today() - v).days\n",
    "        if days_since > 90:\n",
    "            print(f\"‚ö†Ô∏è Patient overdue by {days_since} days\")\n",
    "        return v\n",
    "    \n",
    "    # PROPERTIES - Computed business logic\n",
    "    \n",
    "    @property\n",
    "    def age(self) -> int:\n",
    "        \"\"\"Current age\"\"\"\n",
    "        return (date.today() - self.date_of_birth).days // 365\n",
    "    \n",
    "    @property\n",
    "    def is_pediatric(self) -> bool:\n",
    "        \"\"\"Check if pediatric patient\"\"\"\n",
    "        return self.age < 18\n",
    "    \n",
    "    @property\n",
    "    def treatment_outcome(self) -> str:\n",
    "        \"\"\"WHO treatment outcome classification\"\"\"\n",
    "        if self.viral_load < 1000 and self.cd4_count > 350:\n",
    "            return \"Virological Success\"\n",
    "        elif self.viral_load >= 1000:\n",
    "            return \"Virological Failure\"\n",
    "        else:\n",
    "            return \"Immunological Failure\"\n",
    "    \n",
    "    @property\n",
    "    def next_visit_due(self) -> date:\n",
    "        \"\"\"Calculate next visit date\"\"\"\n",
    "        if self.adherence == \"Poor\":\n",
    "            return self.last_visit + timedelta(days=30)\n",
    "        else:\n",
    "            return self.last_visit + timedelta(days=90)\n",
    "    \n",
    "    @property\n",
    "    def clinical_alert(self) -> str | None:\n",
    "        \"\"\"Generate clinical alerts\"\"\"\n",
    "        alerts = []\n",
    "        \n",
    "        if self.cd4_count < 200:\n",
    "            alerts.append(\"Critical CD4 count\")\n",
    "        \n",
    "        if self.viral_load > 1000 and self.adherence == \"Good\":\n",
    "            alerts.append(\"Treatment failure despite good adherence\")\n",
    "        \n",
    "        days_overdue = (date.today() - self.last_visit).days - 90\n",
    "        if days_overdue > 0:\n",
    "            alerts.append(f\"Overdue by {days_overdue} days\")\n",
    "        \n",
    "        return \"; \".join(alerts) if alerts else None\n",
    "\n",
    "\n",
    "# Usage example\n",
    "if __name__ == \"__main__\":\n",
    "    patient = LAMISPatient(\n",
    "        patient_id=\"LAM12345\",\n",
    "        name=\"John Doe\",\n",
    "        date_of_birth=date(1980, 5, 15),\n",
    "        cd4_count=180,\n",
    "        viral_load=75000,\n",
    "        regimen=\"TDF/3TC/EFV\",\n",
    "        adherence=\"Good\",\n",
    "        last_visit=date(2025, 11, 1)\n",
    "    )\n",
    "\n",
    "    # Validators ran automatically during creation\n",
    "    print(f\"Age: {patient.age}\")\n",
    "    print(f\"Outcome: {patient.treatment_outcome}\")\n",
    "    print(f\"Next Visit: {patient.next_visit_due}\")\n",
    "    print(f\"Alerts: {patient.clinical_alert}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235e7420",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain.schema'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_openai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatOpenAI\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprompts\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatPromptTemplate\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mschema\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RunnableSequence\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# 1. Define tools\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;129m@tool\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_cd4_count\u001b[39m(patient_id: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28mint\u001b[39m:\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'langchain.schema'"
     ]
    }
   ],
   "source": [
    "from langchain.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 1. Define your tools\n",
    "@tool\n",
    "def get_cd4_count(patient_id: str) -> int:\n",
    "    database = {\"LAM12345\": 450, \"LAM67890\": 280}\n",
    "    return database.get(patient_id, 0)\n",
    "\n",
    "@tool\n",
    "def get_viral_load(patient_id: str) -> int:\n",
    "    database = {\"LAM12345\": 50, \"LAM67890\": 75000}\n",
    "    return database.get(patient_id, 0)\n",
    "\n",
    "@tool\n",
    "def recommend_regimen(cd4: int, viral_load: int) -> str:\n",
    "    if viral_load < 1000 and cd4 > 350:\n",
    "        return \"Continue current regimen - patient is stable\"\n",
    "    elif viral_load > 1000:\n",
    "        return \"Consider switching to second-line regimen\"\n",
    "    else:\n",
    "        return \"Intensify adherence counseling\"\n",
    "\n",
    "# 2. Initialize LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# 3. Prompt (optional, for context)\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a medical assistant. Use the available tools to help with patient care.\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "# 4. Use tools directly (manual ‚Äúagent‚Äù style)\n",
    "patient_id = \"LAM67890\"\n",
    "cd4 = get_cd4_count.invoke(patient_id)\n",
    "vl = get_viral_load.invoke(patient_id)\n",
    "recommendation = recommend_regimen.invoke(cd4, vl)\n",
    "\n",
    "print(f\"Patient: {patient_id}\")\n",
    "print(f\"CD4 count: {cd4}\")\n",
    "print(f\"Viral load: {vl}\")\n",
    "print(f\"Recommendation: {recommendation}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
