{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3799c578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi there! How can I help you today ‚Äî a question, writing or coding help, planning something, or something else?\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-5-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Hello!\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70aafe57",
   "metadata": {},
   "source": [
    "## LLM CALL \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9819b9f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Bro ‚Äî fun fact: wombats poop in perfect little cubes.  \\n\\nTheir intestines shape the poop into cubes so it doesn't roll away, which helps them mark territory and communicate. Wildly practical and oddly adorable. Want another one?\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm_openai = ChatOpenAI(model=\"gpt-5-mini\", temperature=0)\n",
    "\n",
    "llm_openai.invoke(\"Bro, tell me a fun fact\").content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc4fb8d",
   "metadata": {},
   "source": [
    "### USING init_chat_model  a factory function that automatically initializes the correct chat model class based on the provider you specify, without needing to import provider-specific classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d44005e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bro ‚Äî fun fact: wombats poop in perfect little cubes. They do it to stack the piles as territorial/attracting markers, and their uniquely-shaped, very slow-moving intestines are what mold the poop into cubes. Want another weird one?'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(\"gpt-5-mini\", model_provider=\"openai\")\n",
    "\n",
    "llm.invoke(\"Bro, tell me a fun fact\").content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b082ee2d",
   "metadata": {},
   "source": [
    "# MESSAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf2dd08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bro, wild fact: bananas are technically berries, but strawberries aren‚Äôt. üçåü§Ø\\n\\nBotanical tea: a ‚Äúberry‚Äù comes from one ovary and has seeds inside ‚Äî bananas check that box. Strawberries are actually aggregate fruits with the seeds on the outside. Mind = blown. Wanna another weird one?'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm_openai = ChatOpenAI(model=\"gpt-5-mini\", temperature=0)\n",
    "\n",
    "my_message = [\n",
    "    HumanMessage(content=\"Bro, tell me a fun fact?\"),\n",
    "    SystemMessage(content=\"You are a gen-z assistance. who always answer in afun way\")\n",
    "]\n",
    "\n",
    "llm_openai.invoke(my_message).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3a84c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1893176779.py, line 3)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mform import load_dotenv import load_dotenv\u001b[39m\n         ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "from load_dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "if os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    print(\"API KEY VARAIBLE EXIST\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
